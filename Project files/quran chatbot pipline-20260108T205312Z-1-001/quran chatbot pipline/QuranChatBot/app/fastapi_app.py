from __future__ import annotations

from typing import Any, Dict, List, Optional

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field

from core import settings
from router.router import DataRouter
from search.retrieval import QuranSearcher, SearchConfig

from llm.openai_client import generate_quran_commentary, generate_pronunciation_guide


app = FastAPI(title="QuranChatBot API", version="1.0.0")

# CORS: adjust allow_origins for VPS / frontend domain later
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

PROJECT_DEFAULT_TOP_K: int = getattr(settings, "default_top_k", 7)

# Router is light; keep global
router = DataRouter(ayahs_json_path="./metadata/ayahs_collection.json")


class QueryRequest(BaseModel):
    query: str = Field(..., min_length=1)
    lang: str = Field("en", description="en | ur | fa | ps")
    top_k: Optional[int] = Field(None, ge=1, le=20)
    show_tafsir: bool = True


class RetrievalInfo(BaseModel):
    method: str
    top_k: int
    reranked: bool
    candidates: List[Dict[str, Any]]


class QuranAnswer(BaseModel):
    answer_language: str
    ayah_ref: str
    ayah_arabic: str
    translation: str
    tafsir_snippet: Optional[str] = None
    response: str
    key_themes: List[str] = []
    cautions: List[str] = []
    retrieval: RetrievalInfo


class PronunciationAnswer(BaseModel):
    answer_language: str
    pronunciation: List[Dict[str, Any]]
    cautions: List[str]


@app.get("/health")
def health() -> Dict[str, str]:
    return {"status": "ok"}


@app.post("/query", response_model=QuranAnswer | PronunciationAnswer)
def query(req: QueryRequest):
    query = (req.query or "").strip()
    if not query:
        raise HTTPException(status_code=422, detail="query is required")

    cfg = SearchConfig(
        qdrant_host=settings.qdrant_host,
        qdrant_port=settings.qdrant_port,
        ayah_collection=settings.qdrant_collection_ayahs,
        word_collection=settings.qdrant_collection_words,
        top_k=req.top_k or PROJECT_DEFAULT_TOP_K,
    )
    searcher = QuranSearcher(cfg)

    routed = router.route(query, ayah_collection=cfg.ayah_collection)

    # Pronunciation path
    if routed.intent == "PRONUNCIATION":
        term = routed.info.get("term", query)
        matches = searcher.pronounce(term, cutoff=85, candidate_k=60, max_return=5)
        if matches:
            return PronunciationAnswer(
                answer_language=req.lang,
                pronunciation=matches,
                cautions=[
                    "Pronunciations may vary slightly by context and case.",
                    "This is a best-effort approximation based on dataset entries.",
                ],
            )

        llm_text = generate_pronunciation_guide(term, lang=req.lang)
        if not llm_text:
            return PronunciationAnswer(
                answer_language=req.lang,
                pronunciation=[],
                cautions=["Could not generate pronunciation guide."],
            )
        return PronunciationAnswer(
            answer_language=req.lang,
            pronunciation=[{"arabic": term, "transliteration": llm_text, "score": 0}],
            cautions=[
                "This guide is generated by an AI model and may be approximate.",
                "For precise recitation consult a qualified teacher.",
            ],
        )

    # Structured vs semantic
    if routed.intent != "SEMANTIC_FALLBACK" and routed.results:
        hits = routed.results
        best = hits[0]
        alts = hits[1:]
        retrieval_method = "structured"
        reranked = False
    else:
        best, alts, _reason = searcher.search_ayahs_best(
            query=query, lang=req.lang, top_k=cfg.top_k, with_alternatives=True
        )
        retrieval_method = "semantic"
        reranked = True
        if best is None:
            raise HTTPException(status_code=404, detail="No relevant ayah found")

    tafsir_dict = best.get("tafsirs") or {}
    tafsir_full = tafsir_dict.get(req.lang) or tafsir_dict.get("en") or ""
    tafsir_snippet = None
    if req.show_tafsir and tafsir_full:
        tafsir_snippet = tafsir_full[:1200] + ("â€¦" if len(tafsir_full) > 1200 else "")

    # Commentary (OpenAI)
    commentary_obj = generate_quran_commentary(
        question=query,
        ayah=best,
        tafsir=tafsir_full,
        lang=req.lang,
        model="gpt-4o-mini",
    )
    response_text = commentary_obj.get("response", "") if isinstance(commentary_obj, dict) else str(commentary_obj)

    candidates: List[Dict[str, Any]] = []
    for h in alts[:5]:
        candidates.append(
            {
                "ref": f"{h.get('surah_num')}:{h.get('ayah_num')}",
                "score": float(h.get("score", 0.0) or 0.0),
            }
        )

    return QuranAnswer(
        answer_language=req.lang,
        ayah_ref=f"{best.get('surah_num')}:{best.get('ayah_num')}",
        ayah_arabic=best.get("arabic") or "",
        translation=(best.get("translations") or {}).get(req.lang)
        or (best.get("translations") or {}).get("en")
        or "",
        tafsir_snippet=tafsir_snippet,
        response=response_text,
        key_themes=commentary_obj.get("key_themes", []) if isinstance(commentary_obj, dict) else [],
        cautions=commentary_obj.get("cautions", ["This is an informational response. For rulings consult a qualified scholar."])
        if isinstance(commentary_obj, dict)
        else ["This is an informational response. For rulings consult a qualified scholar."],
        retrieval=RetrievalInfo(
            method=retrieval_method,
            top_k=cfg.top_k,
            reranked=reranked,
            candidates=candidates,
        ),
    )
